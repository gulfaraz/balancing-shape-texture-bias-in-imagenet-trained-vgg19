{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:11.393458Z",
     "start_time": "2019-01-17T10:28:10.046184Z"
    },
    "cell_style": "split",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# native\n",
    "import os\n",
    "from os import listdir\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import pprint as pp\n",
    "import functools\n",
    "import pickle\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# extra\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "#### Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:11.404838Z",
     "start_time": "2019-01-17T10:28:11.396311Z"
    },
    "cell_style": "split",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requirements = {\n",
    "    torch: '1',\n",
    "    matplotlib: '3'\n",
    "}\n",
    "\n",
    "def check_requirements(requirements):\n",
    "    for requirement in requirements:\n",
    "        error_message = '{} environment does not match requirement'.format(requirement.__name__)\n",
    "        assert (requirement.__version__[0] == requirements[requirement]), error_message\n",
    "\n",
    "check_requirements(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "#### Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:11.466391Z",
     "start_time": "2019-01-17T10:28:11.424672Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:12.052291Z",
     "start_time": "2019-01-17T10:28:11.471203Z"
    },
    "cell_style": "center",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PlotGrid:\n",
    "    def __init__(self, figsize=None):\n",
    "        self.fig = plt.figure(figsize=figsize)\n",
    "        self.ax = {}\n",
    "        self.xlim = {}\n",
    "        self.ylim = {}\n",
    "        self.filled = {}\n",
    "        self.grid = {}\n",
    "    \n",
    "    def plot(self, position_id, data, title=None, xlim=None, ylim=None, filled=None, grid=None):\n",
    "        if position_id in self.ax:\n",
    "            ax = self.ax[position_id]\n",
    "        else:\n",
    "            ax = self.fig.add_subplot(*position_id)\n",
    "\n",
    "        # cache current values\n",
    "        if title is None:\n",
    "            title = ax.get_title()\n",
    "\n",
    "        if xlim is not None:\n",
    "            self.xlim[position_id] = xlim\n",
    "\n",
    "        if ylim is not None:\n",
    "            self.ylim[position_id] = ylim\n",
    "\n",
    "        if filled is not None:\n",
    "            self.filled[position_id] = filled\n",
    "        \n",
    "        if position_id not in self.filled:\n",
    "            self.filled[position_id] = True\n",
    "\n",
    "        if grid is not None:\n",
    "            self.grid[position_id] = grid\n",
    "        \n",
    "        if position_id not in self.grid:\n",
    "            self.grid[position_id] = True\n",
    "\n",
    "        ax.cla()\n",
    "        ax.clear()\n",
    "        if type(data).__name__ == 'Image':\n",
    "            ax.imshow(data)\n",
    "        else:\n",
    "            if hasattr(data, 'is_cuda') and data.is_cuda:\n",
    "                data = data.cpu()\n",
    "            if hasattr(data, 'numpy'):\n",
    "                data = data.numpy()\n",
    "            ax.plot(data)\n",
    "\n",
    "            if self.filled[position_id]:\n",
    "                ax.fill_between(range(len(data)), data)\n",
    "\n",
    "            if self.grid[position_id]:\n",
    "                ax.grid(True)\n",
    "\n",
    "            # set xlim\n",
    "            if position_id in self.xlim:\n",
    "                ax.set_xlim(*self.xlim[position_id])\n",
    "\n",
    "            # set ylim\n",
    "            if position_id in self.ylim:\n",
    "                ax.set_ylim(*self.ylim[position_id])\n",
    "        \n",
    "        # set title\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.canvas.draw()\n",
    "        self.ax[position_id] = ax\n",
    "    \n",
    "    def prediction_plot(self, position_id, data, title=None, grid=None):\n",
    "        if position_id in self.ax:\n",
    "            ax = self.ax[position_id]\n",
    "        else:\n",
    "            ax = self.fig.add_subplot(*position_id)\n",
    "\n",
    "        # cache current values\n",
    "        if title is None:\n",
    "            title = ax.get_title()\n",
    "\n",
    "        if grid is not None:\n",
    "            self.grid[position_id] = grid\n",
    "        \n",
    "        if position_id not in self.grid:\n",
    "            self.grid[position_id] = True\n",
    "\n",
    "        ax.cla()\n",
    "        ax.clear()\n",
    "        plot_data = data[2]\n",
    "        plot_labels = data[1]\n",
    "        if hasattr(plot_data, 'is_cuda') and plot_data.is_cuda:\n",
    "            plot_data = plot_data.cpu()\n",
    "        if hasattr(plot_data, 'numpy'):\n",
    "            plot_data = plot_data.numpy()\n",
    "\n",
    "        ticks = range(len(plot_data)-1, -1, -1)\n",
    "\n",
    "        ax.barh(ticks, plot_data, align='center')\n",
    "\n",
    "        if self.grid[position_id]:\n",
    "            ax.grid(True)\n",
    "\n",
    "        # set xlim\n",
    "        ax.set_xlim(0, 1)\n",
    "\n",
    "        # set y labels\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(plot_labels)\n",
    "        \n",
    "        # set title\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.canvas.draw()\n",
    "        self.ax[position_id] = ax\n",
    "    \n",
    "    def savefig(self, filename):\n",
    "        figure_directory = os.path.join('results', 'plots')\n",
    "        os.makedirs(figure_directory, exist_ok=True)\n",
    "        figure_path = os.path.join(figure_directory, filename)\n",
    "        self.fig.savefig(figure_path, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "#### Test PlotGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:12.581649Z",
     "start_time": "2019-01-17T10:28:12.055084Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# test plotting function\n",
    "plot_grid = PlotGrid(figsize=(9,3))\n",
    "\n",
    "# initialize figures\n",
    "# random\n",
    "data = torch.rand((100))\n",
    "plot_grid.plot((1, 2, 1), data, title='Random', xlim=(0, len(data)), ylim=(0.0, 1.0))\n",
    "# normal\n",
    "data = torch.randn((100))\n",
    "plot_grid.plot((1, 2, 2), data, title='Normal', xlim=(0, len(data)), ylim=(-3.0, 3.0), filled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:16.099571Z",
     "start_time": "2019-01-17T10:28:12.583787Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# update plots\n",
    "for i in range(10):\n",
    "    # random\n",
    "    data = torch.rand((100))\n",
    "    plot_grid.plot((1, 2, 1), data)\n",
    "    # normal\n",
    "    data = torch.randn((100))\n",
    "    plot_grid.plot((1, 2, 2), data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:16.260553Z",
     "start_time": "2019-01-17T10:28:16.101732Z"
    },
    "cell_style": "center",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pathJoin(*args):\n",
    "    return os.path.abspath(os.path.join(*args))\n",
    "\n",
    "\n",
    "def pprint(*args):\n",
    "    pp.pprint(*args)\n",
    "\n",
    "\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def _getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(_getattr, [obj] + attr.split('.'))\n",
    "\n",
    "\n",
    "toPILImage = transforms.ToPILImage()\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def predict(model, dataset, idx, grid, position):\n",
    "    datapoint = dataset[idx]\n",
    "    image = datapoint[1].unsqueeze(0).to(device)\n",
    "    \n",
    "    # convert to probabilities\n",
    "    with torch.no_grad():\n",
    "        output = softmax(model(image))\n",
    "    \n",
    "    # top 1\n",
    "    prediction_probability, predicted_class = output.topk(1, 1, True, True)\n",
    "    prediction_probability = prediction_probability.squeeze()\n",
    "    predicted_class = predicted_class.squeeze()\n",
    "    predicted_description = dataset.descriptions[predicted_class]\n",
    "    top_1 = (predicted_class, predicted_description, prediction_probability)\n",
    "\n",
    "    # top 5\n",
    "    prediction_probability_5, predicted_class_5 = output.topk(5, 1, True, True)\n",
    "    prediction_probability_5 = prediction_probability_5.squeeze()\n",
    "    predicted_class_5 = predicted_class_5.squeeze()\n",
    "    predicted_description_5 = [dataset.descriptions[predicted_class] for predicted_class in predicted_class_5]\n",
    "    top_5 = (predicted_class_5, predicted_description_5, prediction_probability_5)\n",
    "\n",
    "    # all\n",
    "    prediction_probability_all, predicted_class_all = output.topk(output.shape[1], 1, True, True)\n",
    "    prediction_probability_all = prediction_probability_all.squeeze()\n",
    "    predicted_class_all = predicted_class_all.squeeze()\n",
    "    predicted_description_all = [dataset.descriptions[predicted_class] for predicted_class in predicted_class_all]\n",
    "    top_all = (predicted_class_all, predicted_description_all, prediction_probability_all)\n",
    "\n",
    "    if position is not None:\n",
    "        if grid is None:\n",
    "            plt.subplot(*position)\n",
    "            plt.imshow(toImage(datapoint[1]))\n",
    "            plt.title('True: {}\\n Predicted: {}'.format(datapoint[3], predicted_description))\n",
    "        else:\n",
    "            grid.plot(position, toImage(datapoint[1]), title='True: {}'.format(datapoint[3]))\n",
    "            prediction_plot_position = (position[0], position[1], position[2] + 1)\n",
    "            grid.prediction_plot(prediction_plot_position, top_5, title='Predicted: {}'.format(predicted_description))\n",
    "    return (top_1, top_5, top_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset - CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:18.209902Z",
     "start_time": "2019-01-17T10:28:16.276229Z"
    }
   },
   "outputs": [],
   "source": [
    "cifar10_dataset_path = os.path.join('datasets', 'cifar10')\n",
    "\n",
    "cifar10_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "cifar10_train_dataset = datasets.CIFAR10(cifar10_dataset_path,\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=cifar10_transforms)\n",
    "\n",
    "cifar10_test_dataset = datasets.CIFAR10(cifar10_dataset_path,\n",
    "                                         train=False,\n",
    "                                         download=True,\n",
    "                                         transform=cifar10_transforms)\n",
    "\n",
    "cifar10_train_loader = torch.utils.data.DataLoader(cifar10_train_dataset,\n",
    "                                                   batch_size=64,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "\n",
    "cifar10_test_loader = torch.utils.data.DataLoader(cifar10_test_dataset,\n",
    "                                                   batch_size=64,\n",
    "                                                   shuffle=False,\n",
    "                                                   num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset - ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:18.572388Z",
     "start_time": "2019-01-17T10:28:18.522154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, directory, split='train', transforms=None):\n",
    "        self.datapoints = defaultdict(list)\n",
    "        self.split = split\n",
    "        self.directory = pathJoin(directory, split)\n",
    "        self.datapoints = self.loadDataset()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        datapoint = self.loadDatapoint(idx)\n",
    "        return datapoint\n",
    "\n",
    "    def loadDatapoint(self, idx):\n",
    "        raise NotImplementedError('Function \"loadDatapoint\" is not implemented')\n",
    "\n",
    "    def loadDataset(self, name):\n",
    "        raise NotImplementedError('Function \"loadDataset\" is not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:18.876830Z",
     "start_time": "2019-01-17T10:28:18.590251Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageNetDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, directory, split='train', transforms=None):\n",
    "        super().__init__(directory, split, transforms)\n",
    "        self.descriptions = self.loadDescriptions()\n",
    "        self.classes = self.loadClasses()\n",
    "        self.groundtruths = self.loadValidationGroundtruths() if split == 'val' else []\n",
    "\n",
    "    def loadDatapoint(self, idx):\n",
    "        filepath = self.datapoints[idx]\n",
    "        image = Image.open(filepath).convert('RGB')\n",
    "        if self.split == 'val':\n",
    "            groundtruth = self.groundtruths[idx]\n",
    "        elif self.split == 'train':\n",
    "            groundtruth = self.classes.index(filepath.split('/').pop().split('_')[0])\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return (filepath, image, groundtruth, self.descriptions[groundtruth])\n",
    "\n",
    "    def loadDataset(self):\n",
    "        datapoints = []\n",
    "\n",
    "        dataset_file_list_filename = 'ilsvrc2012{}.txt'.format(self.split)\n",
    "        dataset_file_list_path = os.path.join(self.directory, dataset_file_list_filename)\n",
    "\n",
    "        with open(dataset_file_list_path, 'r') as dataset_file_list_file:\n",
    "            for line in tqdm(dataset_file_list_file, total=sum(1 for line in open(dataset_file_list_path))):\n",
    "                file_path = pathJoin(self.directory, self.sanitizeFilename(line))\n",
    "                datapoints.append(file_path)\n",
    "        \n",
    "        return datapoints\n",
    "    \n",
    "    def sanitizeFilename(self, filename):\n",
    "        return filename.replace('\"', '').strip()\n",
    "\n",
    "    def loadDescriptions(self):\n",
    "        descriptions = []\n",
    "\n",
    "        descriptions_filename = 'synsets_with_descriptions.txt'\n",
    "        descriptions_path = pathJoin(self.directory, '..', descriptions_filename)\n",
    "\n",
    "        with open(descriptions_path, 'r') as descriptions_file:\n",
    "            for line in descriptions_file:\n",
    "                description_breakdown = line.split(' ')\n",
    "                description_breakdown.pop(0)\n",
    "                description = ' '.join(description_breakdown).strip()\n",
    "                descriptions.append(description)\n",
    "\n",
    "        return descriptions\n",
    "\n",
    "    def loadValidationGroundtruths(self):\n",
    "        groundtruths = []\n",
    "\n",
    "        groundtruths_filename = 'validation_ground_truth.txt'\n",
    "        groundtruths_path = pathJoin(self.directory, '..', groundtruths_filename)\n",
    "\n",
    "        with open(groundtruths_path, 'r') as groundtruths_file:\n",
    "            for line in groundtruths_file:\n",
    "                groundtruth_breakdown = line.split(' ')\n",
    "                groundtruth_breakdown.pop(0)\n",
    "                groundtruth = ' '.join(groundtruth_breakdown).strip()\n",
    "                groundtruths.append(int(groundtruth))\n",
    "\n",
    "        return groundtruths\n",
    "\n",
    "    def loadClasses(self):\n",
    "        classes = []\n",
    "\n",
    "        classes_filename = 'synsets.txt'\n",
    "        classes_path = pathJoin(self.directory, '..', classes_filename)\n",
    "\n",
    "        with open(classes_path, 'r') as classes_file:\n",
    "            for line in classes_file:\n",
    "                classes.append(line.strip())\n",
    "\n",
    "        return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:19.016030Z",
     "start_time": "2019-01-17T10:28:18.970499Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeNormalize(object):\n",
    "    # Source: https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/3\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:19.730485Z",
     "start_time": "2019-01-17T10:28:19.078862Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "imagenet_normalization_values = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225]\n",
    "}\n",
    "\n",
    "normalize = transforms.Normalize(**imagenet_normalization_values)\n",
    "denormalize = DeNormalize(**imagenet_normalization_values)\n",
    "\n",
    "\n",
    "def toImage(tensor_image):\n",
    "    return toPILImage(denormalize(tensor_image))\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "imagenet_dataset_path = os.path.join('datasets', 'imagenet')\n",
    "\n",
    "# imagenet_train_dataset = ImageNetDataset(imagenet_dataset_path, transforms=test_transforms)\n",
    "imagenet_val_dataset = ImageNetDataset(imagenet_dataset_path, split='val', transforms=test_transforms)\n",
    "# imagenet_test_dataset = ImageNetDataset(imagenet_dataset_path, split='test')\n",
    "\n",
    "# imagenet_train_loader = DataLoader(imagenet_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "imagenet_val_loader = DataLoader(imagenet_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# imagenet_test_loader = DataLoader(imagenet_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:19.775657Z",
     "start_time": "2019-01-17T10:28:19.736996Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "image_grid = PlotGrid(figsize=(9,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:21.440382Z",
     "start_time": "2019-01-17T10:28:19.778610Z"
    },
    "cell_style": "center",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, image in enumerate(imagenet_val_dataset):\n",
    "    img = image[1]\n",
    "    image_grid.plot((1, 1, 1), toImage(img), title=image[3])\n",
    "    if (index + 1) == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:22.649957Z",
     "start_time": "2019-01-17T10:28:21.637212Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:25.002262Z",
     "start_time": "2019-01-17T10:28:24.983592Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet_validation_grid = PlotGrid(figsize=(9,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:47.086744Z",
     "start_time": "2019-01-17T10:28:25.307236Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "imagenet_validation_grid.plot((1, 2, 1), torch.tensor(accuracy), title='Validation Accuracy', filled=False, ylim=(0,1))\n",
    "\n",
    "for index, batch in enumerate(imagenet_val_loader):\n",
    "    output = resnet50(batch[1].to(device))\n",
    "    _, predicted_class = output.topk(1, 1, True, True)\n",
    "    predicted_descriptions = [ imagenet_val_dataset.descriptions[x] for x in predicted_class.squeeze() ]\n",
    "    batch_accuracy = accuracy_score(batch[2], predicted_class.cpu().squeeze())\n",
    "    accuracy.append(batch_accuracy)\n",
    "    imagenet_validation_grid.plot((1, 2, 1), torch.tensor(accuracy), title='Validation Accuracy {0:.4f}'.format(np.mean(accuracy)))\n",
    "    imagenet_validation_grid.plot((1, 2, 2), toImage(batch[1][0]), title='True: {}\\n Predicted: {}'.format(batch[3][0], predicted_descriptions[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:47.104077Z",
     "start_time": "2019-01-17T10:28:47.090481Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction_grid = PlotGrid(figsize=(9,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:47.937966Z",
     "start_time": "2019-01-17T10:28:47.105877Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict(resnet50, imagenet_val_dataset, 0, prediction_grid, (1, 2, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hook and Hooker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T21:57:18.558076Z",
     "start_time": "2019-01-16T21:57:18.535350Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_plot_index(name, index, normalize, plot=False):\n",
    "    def print_output(self, input, output):\n",
    "        data = output.data.squeeze()\n",
    "        if self.__class__.__name__ != 'Linear':\n",
    "            data = data.norm(dim=(1, 2))\n",
    "        if normalize:\n",
    "            data = data.unsqueeze(0)\n",
    "            data = data.renorm(1, 0, 1)\n",
    "            data = data.squeeze()\n",
    "        data = data.cpu().numpy()\n",
    "        \n",
    "        # value\n",
    "        activations[name] = data\n",
    "        \n",
    "        # plot\n",
    "        if plot:\n",
    "            plt.subplot(*index)\n",
    "            plt.plot(data)\n",
    "            plt.fill_between(range(len(data)), data)\n",
    "            plt.grid(True)\n",
    "            plt.title(name)\n",
    "    return print_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add hooks to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T21:57:18.589597Z",
     "start_time": "2019-01-16T21:57:18.562751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_hooks(model, hooker, nrows=2, ncols=2, normalize=False):\n",
    "    names = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        name = name.split('.')\n",
    "        name.pop()\n",
    "        name = '.'.join(name)\n",
    "        names[name] = None\n",
    "\n",
    "    names = list(names)\n",
    "    for index, name in enumerate(names):\n",
    "        module = rgetattr(model, name)\n",
    "        module.register_forward_hook(hooker(name, (nrows, ncols, index + 1), normalize))\n",
    "\n",
    "# add hooks to resnet50\n",
    "add_hooks(resnet50, assign_plot_index, nrows=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.430663Z",
     "start_time": "2019-01-17T10:28:47.940103Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values_directory = os.path.join('results', 'values')\n",
    "\n",
    "# for imagenet_val_index, datapoint in enumerate(imagenet_val_dataset):\n",
    "#     activations = {}\n",
    "#     predicted_class, prediction_description = predict(resnet50, imagenet_val_dataset, imagenet_val_index, None, None)\n",
    "#     true_class = datapoint[2]\n",
    "#     values_path = os.path.join(values_directory, '{}-{}-{}.pickle'.format(imagenet_val_index, true_class, predicted_class))\n",
    "#     pickle.dump(activations, open(values_path, 'wb'))\n",
    "\n",
    "def get_sort_key(name):\n",
    "    return int(name.split('/')[-1].split('.')[0].split('-')[0])\n",
    "\n",
    "activations_file_list = sorted(\n",
    "    [os.path.join(values_directory, file) for file in listdir(values_directory)],\n",
    "    key=get_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.477524Z",
     "start_time": "2019-01-17T10:28:48.432644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_activations(activations, imagenet_val_index, true_class, predicted_class):\n",
    "    activation_grid = PlotGrid(figsize=(9,90))\n",
    "    for index, name in enumerate(activations):\n",
    "        data = activations[name]\n",
    "        activation_grid.plot((54, 2, index+1), data, title=name)\n",
    "\n",
    "    # plot image\n",
    "    activation_grid.plot(\n",
    "        (54, 2, 108),\n",
    "        toImage(imagenet_val_dataset[imagenet_val_index][1]),\n",
    "        title='True: {}\\n Predicted: {}'.format(\n",
    "            imagenet_val_dataset.descriptions[predicted_class],\n",
    "            imagenet_val_dataset.descriptions[true_class]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # save figure\n",
    "    activation_grid.savefig('{}-{}-{}.png'.format(imagenet_val_index, true_class, predicted_class))\n",
    "\n",
    "\n",
    "def load_activations(activation_file_index):\n",
    "    activations_file_path = activations_file_list[activation_file_index]\n",
    "    imagenet_val_index, true_class, predicted_class = activations_file_list[activation_file_index].split('/')[-1].split('.')[0].split('-')\n",
    "    return pickle.load(open(activations_file_path, 'rb')), int(imagenet_val_index), int(true_class), int(predicted_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.491081Z",
     "start_time": "2019-01-17T10:28:48.480289Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, name in enumerate(activations_file_list):\n",
    "    activations, imagenet_val_index, true_class, predicted_class = load_activations(index)\n",
    "#     plot_activations(activations, imagenet_val_index, true_class, predicted_class)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.514126Z",
     "start_time": "2019-01-17T10:28:48.494049Z"
    }
   },
   "outputs": [],
   "source": [
    "def JSDiv(p, q):\n",
    "    return torch.nn.KLDivLoss(reduction='sum')(p.log(), q) + torch.nn.KLDivLoss(reduction='sum')(q.log(), p)\n",
    "\n",
    "# test inputs\n",
    "p = torch.FloatTensor([0.3, 0.6, 0.1])\n",
    "q = torch.FloatTensor([0.4, 0.5, 0.1])\n",
    "\n",
    "# test call\n",
    "print('{0:.4f} JS Divergence'.format(JSDiv(p, q).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.537784Z",
     "start_time": "2019-01-17T10:28:48.517225Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_activation(activations, layer_name):\n",
    "    data = torch.from_numpy(activations[layer_name])\n",
    "    if layer_name == 'fc':\n",
    "        data = torch.nn.Softmax(dim=0)(data)\n",
    "    else:\n",
    "        data = data.unsqueeze(0)\n",
    "        data = data.renorm(1, 0, 1)\n",
    "        data = data.squeeze()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.562023Z",
     "start_time": "2019-01-17T10:28:48.541549Z"
    }
   },
   "outputs": [],
   "source": [
    "activations_1, _, _, _ = load_activations(1)\n",
    "activations_2, _, _, _ = load_activations(2)\n",
    "\n",
    "layer_names = list(activations_2.keys())\n",
    "layer_index = -3\n",
    "\n",
    "p = get_layer_activation(activations_1, layer_names[layer_index])\n",
    "q = get_layer_activation(activations_2, layer_names[layer_index])\n",
    "\n",
    "assert np.isclose(p.sum().item(), 1), 'activations (p) is not a distribution'\n",
    "assert np.isclose(q.sum().item(), 1), 'activations (q) is not a distribution'\n",
    "\n",
    "print('{0:.4f} JS Divergence of activations at layer \"{1}\"'.format(JSDiv(q, p).item(), layer_names[layer_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate divergence for multiple images given a reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.590505Z",
     "start_time": "2019-01-17T10:28:48.567856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_divergence(target_index, compare_indices, layer_name):\n",
    "    activations, imagenet_val_index, true_class, predicted_class = load_activations(target_index)\n",
    "    p = get_layer_activation(activations, layer_name)\n",
    "    divergence_information = []\n",
    "    for compare_index in compare_indices:\n",
    "        activations_, imagenet_val_index_, true_class_, predicted_class_  = load_activations(compare_index)\n",
    "        q = get_layer_activation(activations_, layer_name)\n",
    "        divergence_information.append((\n",
    "            JSDiv(p, q).item(),\n",
    "            true_class==true_class_,\n",
    "            predicted_class==predicted_class_,\n",
    "            true_class==predicted_class,\n",
    "            imagenet_val_index,\n",
    "            imagenet_val_index_\n",
    "        ))\n",
    "    return divergence_information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:28:48.622294Z",
     "start_time": "2019-01-17T10:28:48.595370Z"
    }
   },
   "outputs": [],
   "source": [
    "divergence_values_directory = os.path.join('results', 'divergence-values')\n",
    "os.makedirs(divergence_values_directory, exist_ok=True)\n",
    "\n",
    "divergence_figure_directory = os.path.join('results', 'divergence-plots')\n",
    "os.makedirs(divergence_figure_directory, exist_ok=True)\n",
    "\n",
    "def get_sort_key(name):\n",
    "    return int(name.split('/')[-1].split('.')[0].split('-')[1])\n",
    "\n",
    "divergences_file_list = sorted(\n",
    "    [os.path.join(divergence_values_directory, file) for file in listdir(divergence_values_directory)],\n",
    "    key=get_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate/Plot activation divergence at specified layers given the reference image over the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T10:30:01.883840Z",
     "start_time": "2019-01-17T10:30:01.801252Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_divergences(datapoint_index, save=True):\n",
    "    other_indices = list(range(0, len(imagenet_val_dataset)))\n",
    "    other_indices.remove(datapoint_index)\n",
    "    divergence_information = {}\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergence_information[layer_name] = activation_divergence(datapoint_index, other_indices, layer_name)\n",
    "    if save:\n",
    "        values_path = os.path.join(divergence_values_directory, 'divergence-{}.pickle'.format(datapoint_index))\n",
    "        pickle.dump(divergence_information, open(values_path, 'wb'))\n",
    "    return divergence_information\n",
    "\n",
    "\n",
    "def load_divergences(divergences_file_index):\n",
    "    divergences_file_path = divergences_file_list[divergences_file_index]\n",
    "    _, imagenet_val_index = divergences_file_list[divergences_file_index].split('/')[-1].split('.')[0].split('-')\n",
    "    return pickle.load(open(divergences_file_path, 'rb')), int(imagenet_val_index)\n",
    "\n",
    "\n",
    "def plot_divergences(divergence_information, datapoint_index, cols=2, same_class_size=100, other_class_size=1, save=True):\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergences = [ x[0] for x in divergence_information[layer_name] ]\n",
    "        class_matches = [ int(x[1]) for x in divergence_information[layer_name] ]\n",
    "        class_matches_size = [ same_class_size if x==1 else other_class_size for x in class_matches ]\n",
    "        plt.subplot(len(layer_names)//cols + len(layer_names)%cols, cols, index)\n",
    "        plt.scatter(range(len(divergences)), divergences, s=class_matches_size, c=class_matches)\n",
    "        plt.title(layer_name)\n",
    "        plt.show()\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(divergence_figure_directory, 'divergence-{}.png'.format(datapoint_index)), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Min/Mean/Max Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-17T16:54:15.323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_zeros(array):\n",
    "    return array[np.flatnonzero(array)]\n",
    "\n",
    "def calculate_divergence_metrics(divergence_information):\n",
    "    metrics = {}\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergences = np.array([ x[0] for x in divergence_information[layer_name] ])\n",
    "        class_matches = np.array([ int(x[1]) for x in divergence_information[layer_name] ])\n",
    "        other_class = (class_matches + 1) % 2\n",
    "        class_divergences = remove_zeros(divergences * class_matches)\n",
    "        other_divergences = remove_zeros(divergences * other_class)\n",
    "        metrics[layer_name] = {\n",
    "            'same': {\n",
    "                'min': class_divergences.min(),\n",
    "                'mean': class_divergences.mean(),\n",
    "                'max': class_divergences.max()\n",
    "            },\n",
    "            'other': {\n",
    "                'min': other_divergences.min(),\n",
    "                'mean': other_divergences.mean(),\n",
    "                'max': other_divergences.max()\n",
    "            }\n",
    "        }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate activation divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-17T16:54:38.188Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "divergence_metrics = {}\n",
    "\n",
    "for datapoint_index in range(len(imagenet_val_dataset)):\n",
    "    divergence_information = calculate_divergences(datapoint_index)\n",
    "    divergence_metrics[datapoint_index] = calculate_divergence_metrics(divergence_information)\n",
    "\n",
    "metrics_path = os.path.join(divergence_values_directory, 'divergence-metrics.pickle')\n",
    "pickle.dump(divergence_metrics, open(metrics_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot activation divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-17T16:54:58.019Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, len(layer_names) * 2))\n",
    "for index, name in enumerate(divergences_file_list):\n",
    "    divergence_information, imagenet_val_index = load_divergences(index)\n",
    "    plot_divergences(divergence_information, imagenet_val_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml1labs]",
   "language": "python",
   "name": "conda-env-ml1labs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
