{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Elephant Cat Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:45.006827Z",
     "start_time": "2019-02-12T23:25:42.516719Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# native\n",
    "import os\n",
    "from os import listdir\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import pprint as pp\n",
    "import functools\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# extra\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "#### Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:45.024019Z",
     "start_time": "2019-02-12T23:25:45.012138Z"
    },
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "requirements = {\n",
    "    torch: '1',\n",
    "    matplotlib: '3'\n",
    "}\n",
    "\n",
    "def check_requirements(requirements):\n",
    "    for requirement in requirements:\n",
    "        error_message = '{} environment does not match requirement'.format(requirement.__name__)\n",
    "        assert (requirement.__version__[0] == requirements[requirement]), error_message\n",
    "\n",
    "check_requirements(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "#### Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:45.053385Z",
     "start_time": "2019-02-12T23:25:45.028674Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:19:34.230777Z",
     "start_time": "2019-02-12T23:19:34.142298Z"
    },
    "cell_style": "center",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PlotGrid:\n",
    "    def __init__(self, figsize=None):\n",
    "        self.fig = plt.figure(figsize=figsize)\n",
    "        self.ax = {}\n",
    "        self.xlim = {}\n",
    "        self.ylim = {}\n",
    "        self.filled = {}\n",
    "        self.grid = {}\n",
    "    \n",
    "    def plot(self, position_id, data, title=None, xlim=None, ylim=None, filled=None, grid=None):\n",
    "        if position_id in self.ax:\n",
    "            ax = self.ax[position_id]\n",
    "        else:\n",
    "            ax = self.fig.add_subplot(*position_id)\n",
    "\n",
    "        # cache current values\n",
    "        if title is None:\n",
    "            title = ax.get_title()\n",
    "\n",
    "        if xlim is not None:\n",
    "            self.xlim[position_id] = xlim\n",
    "\n",
    "        if ylim is not None:\n",
    "            self.ylim[position_id] = ylim\n",
    "\n",
    "        if filled is not None:\n",
    "            self.filled[position_id] = filled\n",
    "        \n",
    "        if position_id not in self.filled:\n",
    "            self.filled[position_id] = True\n",
    "\n",
    "        if grid is not None:\n",
    "            self.grid[position_id] = grid\n",
    "        \n",
    "        if position_id not in self.grid:\n",
    "            self.grid[position_id] = True\n",
    "\n",
    "        ax.cla()\n",
    "        ax.clear()\n",
    "        if type(data).__name__ == 'Image':\n",
    "            ax.imshow(data)\n",
    "        else:\n",
    "            if hasattr(data, 'is_cuda') and data.is_cuda:\n",
    "                data = data.cpu()\n",
    "            if hasattr(data, 'numpy'):\n",
    "                data = data.numpy()\n",
    "            ax.plot(data)\n",
    "\n",
    "            if self.filled[position_id]:\n",
    "                ax.fill_between(range(len(data)), data)\n",
    "\n",
    "            if self.grid[position_id]:\n",
    "                ax.grid(True)\n",
    "\n",
    "            # set xlim\n",
    "            if position_id in self.xlim:\n",
    "                ax.set_xlim(*self.xlim[position_id])\n",
    "\n",
    "            # set ylim\n",
    "            if position_id in self.ylim:\n",
    "                ax.set_ylim(*self.ylim[position_id])\n",
    "        \n",
    "        # set title\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.canvas.draw()\n",
    "        self.ax[position_id] = ax\n",
    "    \n",
    "    def prediction_plot(self, position_id, data, title=None, grid=None):\n",
    "        if position_id in self.ax:\n",
    "            ax = self.ax[position_id]\n",
    "        else:\n",
    "            ax = self.fig.add_subplot(*position_id)\n",
    "\n",
    "        # cache current values\n",
    "        if title is None:\n",
    "            title = ax.get_title()\n",
    "\n",
    "        if grid is not None:\n",
    "            self.grid[position_id] = grid\n",
    "        \n",
    "        if position_id not in self.grid:\n",
    "            self.grid[position_id] = True\n",
    "\n",
    "        ax.cla()\n",
    "        ax.clear()\n",
    "        plot_data = data[2]\n",
    "        plot_labels = data[1]\n",
    "        if hasattr(plot_data, 'is_cuda') and plot_data.is_cuda:\n",
    "            plot_data = plot_data.cpu()\n",
    "        if hasattr(plot_data, 'numpy'):\n",
    "            plot_data = plot_data.numpy()\n",
    "\n",
    "        ticks = range(len(plot_data)-1, -1, -1)\n",
    "\n",
    "        ax.barh(ticks, plot_data, align='center')\n",
    "\n",
    "        if self.grid[position_id]:\n",
    "            ax.grid(True)\n",
    "\n",
    "        # set xlim\n",
    "        ax.set_xlim(0, 1)\n",
    "\n",
    "        # set y labels\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(plot_labels)\n",
    "        \n",
    "        # set title\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.canvas.draw()\n",
    "        self.ax[position_id] = ax\n",
    "    \n",
    "    def savefig(self, filename):\n",
    "        figure_directory = os.path.join('results', 'elephant-cat', 'activation-plots')\n",
    "        os.makedirs(figure_directory, exist_ok=True)\n",
    "        figure_path = os.path.join(figure_directory, filename)\n",
    "        self.fig.savefig(figure_path, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "#### Test PlotGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:20.976174Z",
     "start_time": "2019-01-29T15:14:16.559397Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# test plotting function\n",
    "plot_grid = PlotGrid(figsize=(9,3))\n",
    "\n",
    "# initialize figures\n",
    "# random\n",
    "data = torch.rand((100))\n",
    "plot_grid.plot((1, 2, 1), data, title='Random', xlim=(0, len(data)), ylim=(0.0, 1.0))\n",
    "# normal\n",
    "data = torch.randn((100))\n",
    "plot_grid.plot((1, 2, 2), data, title='Normal', xlim=(0, len(data)), ylim=(-3.0, 3.0), filled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:28.378283Z",
     "start_time": "2019-01-29T15:14:20.980885Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# update plots\n",
    "for i in range(10):\n",
    "    # random\n",
    "    data = torch.rand((100))\n",
    "    plot_grid.plot((1, 2, 1), data)\n",
    "    # normal\n",
    "    data = torch.randn((100))\n",
    "    plot_grid.plot((1, 2, 2), data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:49.172720Z",
     "start_time": "2019-02-12T23:25:49.115388Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def pathJoin(*args):\n",
    "    return os.path.abspath(os.path.join(*args))\n",
    "\n",
    "\n",
    "def pprint(*args):\n",
    "    pp.pprint(*args)\n",
    "\n",
    "\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def _getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(_getattr, [obj] + attr.split('.'))\n",
    "\n",
    "\n",
    "toPILImage = transforms.ToPILImage()\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def predict(model, dataset, idx, grid, position):\n",
    "    datapoint = dataset[idx]\n",
    "    image = datapoint[1].unsqueeze(0).to(device)\n",
    "    \n",
    "    # convert to probabilities\n",
    "    with torch.no_grad():\n",
    "        output = softmax(model(image))\n",
    "    \n",
    "    # top 1\n",
    "    prediction_probability, predicted_class = output.topk(1, 1, True, True)\n",
    "    prediction_probability = prediction_probability.squeeze()\n",
    "    predicted_class = predicted_class.squeeze()\n",
    "    predicted_description = dataset.descriptions[predicted_class]\n",
    "    top_1 = (predicted_class, predicted_description, prediction_probability)\n",
    "\n",
    "    # top 5\n",
    "    prediction_probability_5, predicted_class_5 = output.topk(5, 1, True, True)\n",
    "    prediction_probability_5 = prediction_probability_5.squeeze()\n",
    "    predicted_class_5 = predicted_class_5.squeeze()\n",
    "    predicted_description_5 = [dataset.descriptions[predicted_class] for predicted_class in predicted_class_5]\n",
    "    top_5 = (predicted_class_5, predicted_description_5, prediction_probability_5)\n",
    "\n",
    "    # all\n",
    "    prediction_probability_all, predicted_class_all = output.topk(output.shape[1], 1, True, True)\n",
    "    prediction_probability_all = prediction_probability_all.squeeze()\n",
    "    predicted_class_all = predicted_class_all.squeeze()\n",
    "    predicted_description_all = [dataset.descriptions[predicted_class] for predicted_class in predicted_class_all]\n",
    "    top_all = (predicted_class_all, predicted_description_all, prediction_probability_all)\n",
    "\n",
    "    if position is not None:\n",
    "        if grid is None:\n",
    "            plt.subplot(*position)\n",
    "            plt.imshow(toImage(datapoint[1]))\n",
    "            plt.title('True: {}\\n Predicted: {}'.format(datapoint[3], predicted_description))\n",
    "        else:\n",
    "            grid.plot(position, toImage(datapoint[1]), title='True: {}'.format(datapoint[3]))\n",
    "            prediction_plot_position = (position[0], position[1], position[2] + 1)\n",
    "            grid.prediction_plot(prediction_plot_position, top_5, title='Predicted: {}'.format(predicted_description))\n",
    "    return (top_1, top_5, top_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset - ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:51.321544Z",
     "start_time": "2019-02-12T23:25:51.301706Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, directory, split='train', transforms=None):\n",
    "        self.datapoints = defaultdict(list)\n",
    "        self.split = split\n",
    "        self.directory = pathJoin(directory, split)\n",
    "        self.datapoints = self.loadDataset()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        datapoint = self.loadDatapoint(idx)\n",
    "        return datapoint\n",
    "\n",
    "    def loadDatapoint(self, idx):\n",
    "        raise NotImplementedError('Function \"loadDatapoint\" is not implemented')\n",
    "\n",
    "    def loadDataset(self, name):\n",
    "        raise NotImplementedError('Function \"loadDataset\" is not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:51.665162Z",
     "start_time": "2019-02-12T23:25:51.601020Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageNetDataset(BaseDataset):\n",
    "\n",
    "    def __init__(self, directory, split='train', transforms=None):\n",
    "        super().__init__(directory, split, transforms)\n",
    "        self.descriptions = self.loadDescriptions()\n",
    "        self.classes = self.loadClasses()\n",
    "        self.groundtruths = self.loadValidationGroundtruths() if split == 'val' else []\n",
    "\n",
    "    def loadDatapoint(self, idx):\n",
    "        filepath = self.datapoints[idx]\n",
    "        image = Image.open(filepath).convert('RGB')\n",
    "        if self.split == 'val':\n",
    "            groundtruth = self.groundtruths[idx]\n",
    "        elif self.split == 'train':\n",
    "            groundtruth = self.classes.index(filepath.split('/').pop().split('_')[0])\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return (filepath, image, groundtruth, self.descriptions[groundtruth])\n",
    "\n",
    "    def loadDataset(self):\n",
    "        datapoints = []\n",
    "\n",
    "        dataset_file_list_filename = 'ilsvrc2012{}.txt'.format(self.split)\n",
    "        dataset_file_list_path = os.path.join(self.directory, dataset_file_list_filename)\n",
    "\n",
    "        with open(dataset_file_list_path, 'r') as dataset_file_list_file:\n",
    "            for line in tqdm(dataset_file_list_file, total=sum(1 for line in open(dataset_file_list_path))):\n",
    "                file_path = pathJoin(self.directory, self.sanitizeFilename(line))\n",
    "                datapoints.append(file_path)\n",
    "        \n",
    "        return datapoints\n",
    "    \n",
    "    def sanitizeFilename(self, filename):\n",
    "        return filename.replace('\"', '').strip()\n",
    "\n",
    "    def loadDescriptions(self):\n",
    "        descriptions = []\n",
    "\n",
    "        descriptions_filename = 'synsets_with_descriptions.txt'\n",
    "        descriptions_path = pathJoin(self.directory, '..', descriptions_filename)\n",
    "\n",
    "        with open(descriptions_path, 'r') as descriptions_file:\n",
    "            for line in descriptions_file:\n",
    "                description_breakdown = line.split(' ')\n",
    "                description_breakdown.pop(0)\n",
    "                description = ' '.join(description_breakdown).strip()\n",
    "                descriptions.append(description)\n",
    "\n",
    "        return descriptions\n",
    "\n",
    "    def loadValidationGroundtruths(self):\n",
    "        groundtruths = []\n",
    "\n",
    "        groundtruths_filename = 'validation_ground_truth.txt'\n",
    "        groundtruths_path = pathJoin(self.directory, '..', groundtruths_filename)\n",
    "\n",
    "        with open(groundtruths_path, 'r') as groundtruths_file:\n",
    "            for line in groundtruths_file:\n",
    "                groundtruth_breakdown = line.split(' ')\n",
    "                groundtruth_breakdown.pop(0)\n",
    "                groundtruth = ' '.join(groundtruth_breakdown).strip()\n",
    "                groundtruths.append(int(groundtruth))\n",
    "\n",
    "        return groundtruths\n",
    "\n",
    "    def loadClasses(self):\n",
    "        classes = []\n",
    "\n",
    "        classes_filename = 'synsets.txt'\n",
    "        classes_path = pathJoin(self.directory, '..', classes_filename)\n",
    "\n",
    "        with open(classes_path, 'r') as classes_file:\n",
    "            for line in classes_file:\n",
    "                classes.append(line.strip())\n",
    "\n",
    "        return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:53.247835Z",
     "start_time": "2019-02-12T23:25:53.231525Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeNormalize(object):\n",
    "    # Source: https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/3\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        tensor = image.clone()\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:25:56.391421Z",
     "start_time": "2019-02-12T23:25:54.342090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 28053.39it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "imagenet_normalization_values = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225]\n",
    "}\n",
    "\n",
    "normalize = transforms.Normalize(**imagenet_normalization_values)\n",
    "denormalize = DeNormalize(**imagenet_normalization_values)\n",
    "\n",
    "\n",
    "def toImage(tensor_image):\n",
    "    return toPILImage(denormalize(tensor_image))\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "imagenet_dataset_path = os.path.join('datasets', 'imagenet')\n",
    "\n",
    "# imagenet_train_dataset = ImageNetDataset(imagenet_dataset_path, transforms=test_transforms)\n",
    "imagenet_val_dataset = ImageNetDataset(imagenet_dataset_path, split='val', transforms=test_transforms)\n",
    "# imagenet_test_dataset = ImageNetDataset(imagenet_dataset_path, split='test')\n",
    "\n",
    "# imagenet_train_loader = DataLoader(imagenet_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "imagenet_val_loader = DataLoader(imagenet_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# imagenet_test_loader = DataLoader(imagenet_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:26:01.340437Z",
     "start_time": "2019-02-12T23:25:57.095936Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:26:02.411053Z",
     "start_time": "2019-02-12T23:26:02.382461Z"
    }
   },
   "outputs": [],
   "source": [
    "def stats(prediction, target):\n",
    "    total = prediction.size(0)\n",
    "    prediction = prediction.t()\n",
    "    correct = prediction.eq(target.view(1, -1).expand_as(prediction))\n",
    "    top1 = correct[:1].view(-1).float().sum(0).item()\n",
    "    top5 = correct[:5].view(-1).float().sum(0).item()\n",
    "    return top1, top5, total\n",
    "\n",
    "def score_model(model, dataloader):\n",
    "    total_top1 = 0\n",
    "    total_top5 = 0\n",
    "    total_ = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        target = batch[2].to(device)\n",
    "        input = batch[1].to(device)\n",
    "        output = model(input)\n",
    "        _, predicted_classes = output.topk(5, 1, True, True)\n",
    "        top1, top5, total = stats(predicted_classes, target)\n",
    "        total_top1 += top1\n",
    "        total_top5 += top5\n",
    "        total_ += total\n",
    "    return total_top1/total_, total_top5/total_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:41:22.879888Z",
     "start_time": "2019-02-12T23:26:03.030181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [15:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.74548, 0.9201)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(resnet50, imagenet_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T00:27:23.217742Z",
     "start_time": "2019-02-12T23:41:22.885810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet50_trained_on_SIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [15:18<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.55478, 0.78786)\n",
      "\n",
      "\n",
      "Model: resnet50_trained_on_SIN_and_IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [15:17<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.72628, 0.90934)\n",
      "\n",
      "\n",
      "Model: resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [15:18<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7543, 0.92456)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_name):\n",
    "\n",
    "    model_urls = {\n",
    "            'resnet50_trained_on_SIN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/6f41d2e86fc60566f78de64ecff35cc61eb6436f/resnet50_train_60_epochs-c8e5653e.pth.tar',\n",
    "            'resnet50_trained_on_SIN_and_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_train_45_epochs_combined_IN_SF-2a0d100e.pth.tar',\n",
    "            'resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_finetune_60_epochs_lr_decay_after_30_start_resnet50_train_45_epochs_combined_IN_SF-ca06340c.pth.tar',\n",
    "    }\n",
    "\n",
    "    model = torchvision.models.resnet50(pretrained=False)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    checkpoint = model_zoo.load_url(model_urls[model_name])\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "for model in ['resnet50_trained_on_SIN', 'resnet50_trained_on_SIN_and_IN', 'resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN']:\n",
    "    print('Model: {}'.format(model))\n",
    "    model = load_model(model)\n",
    "    model.eval()\n",
    "    print(score_model(model, imagenet_val_loader))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elephant Cat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:31.509494Z",
     "start_time": "2019-01-29T15:14:31.405318Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_filepath = os.path.join('elephant-cat-experiment', 'cat.png')\n",
    "cat_image = Image.open(cat_filepath).convert('RGB')\n",
    "\n",
    "stylized_cat_filepath = os.path.join('elephant-cat-experiment', 'stylized_cat.jpg')\n",
    "stylized_cat_image = Image.open(stylized_cat_filepath).convert('RGB')\n",
    "\n",
    "blog_cat_filepath = os.path.join('elephant-cat-experiment', 'cat7-elephant1.png')\n",
    "blog_cat_image = Image.open(blog_cat_filepath).convert('RGB')\n",
    "\n",
    "elephant_texture_filepath = os.path.join('elephant-cat-experiment', 'elephant_texture.jpg')\n",
    "elephant_texture_image = Image.open(elephant_texture_filepath).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:31.681882Z",
     "start_time": "2019-01-29T15:14:31.514497Z"
    }
   },
   "outputs": [],
   "source": [
    "# asian_elephant, african_bush_elephant = None, None\n",
    "\n",
    "# for index, i in enumerate(imagenet_val_dataset):\n",
    "#     if asian_elephant is not None and african_bush_elephant is not None:\n",
    "#         break\n",
    "#     if i[3] == 'Asian elephant':\n",
    "#         print('x {}'.format(index))\n",
    "#         asian_elephant = i\n",
    "#     if i[3] == 'African bush elephant':\n",
    "#         print('y {}'.format(index))\n",
    "#         african_bush_elephant = i\n",
    "\n",
    "asian_elephant = imagenet_val_dataset[11246]\n",
    "african_bush_elephant = imagenet_val_dataset[10618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:31.993504Z",
     "start_time": "2019-01-29T15:14:31.686055Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "def show_image(image, position, title):\n",
    "    plt.subplot(*position)\n",
    "    plt.imshow(toImage(test_transforms(image)))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "show_image(cat_image, (2, 3, 1), 'original')\n",
    "show_image(elephant_texture_image, (2, 3, 2), 'texture')\n",
    "show_image(stylized_cat_image, (2, 3, 3), 'stylized')\n",
    "show_image(blog_cat_image, (2, 3, 4), 'blog')\n",
    "show_image(toImage(asian_elephant[1]), (2, 3, 5), 'asian elephant')\n",
    "show_image(toImage(african_bush_elephant[1]), (2, 3, 6), 'african bush elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T23:03:34.524321Z",
     "start_time": "2019-02-12T23:03:33.802877Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Elephant_Cat_Dataset(list):\n",
    "    def __new__(self, *args, **kwargs):\n",
    "        return super(Elephant_Cat_Dataset, self).__new__(self, args, kwargs)\n",
    "\n",
    "# override true class ids\n",
    "asian_elephant = (asian_elephant[0], asian_elephant[1], 4, asian_elephant[3])\n",
    "african_bush_elephant = (african_bush_elephant[0], african_bush_elephant[1], 5, african_bush_elephant[3])\n",
    "\n",
    "elephant_cat_datapoints = [\n",
    "    (None, test_transforms(cat_image), 0, 'original cat'),\n",
    "    (None, test_transforms(elephant_texture_image), 1, 'elephant texture'),\n",
    "    (None, test_transforms(stylized_cat_image), 2, 'stylized cat'),\n",
    "    (None, test_transforms(blog_cat_image), 3, 'blog cat'),\n",
    "    asian_elephant,\n",
    "    african_bush_elephant\n",
    "]\n",
    "\n",
    "def create_elephant_cat_dataset():\n",
    "    elephant_cat_dataset = Elephant_Cat_Dataset(elephant_cat_datapoints)\n",
    "\n",
    "    setattr(elephant_cat_dataset, 'descriptions', imagenet_val_dataset.descriptions)\n",
    "    return elephant_cat_dataset\n",
    "\n",
    "elephant_cat_dataset = create_elephant_cat_dataset()\n",
    "\n",
    "def test_model(model):\n",
    "    elephant_cat_grid = PlotGrid(figsize=(9,18))\n",
    "    for i in range(len(elephant_cat_datapoints)):\n",
    "        predict(model, elephant_cat_dataset, i, elephant_cat_grid, (len(elephant_cat_datapoints), 2, ((i * 2) + 1) ));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:14:45.112230Z",
     "start_time": "2019-01-29T15:14:32.061559Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:15:19.251756Z",
     "start_time": "2019-01-29T15:14:45.116517Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "\n",
    "    model_urls = {\n",
    "            'resnet50_trained_on_SIN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/6f41d2e86fc60566f78de64ecff35cc61eb6436f/resnet50_train_60_epochs-c8e5653e.pth.tar',\n",
    "            'resnet50_trained_on_SIN_and_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_train_45_epochs_combined_IN_SF-2a0d100e.pth.tar',\n",
    "            'resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN': 'https://bitbucket.org/robert_geirhos/texture-vs-shape-pretrained-models/raw/60b770e128fffcbd8562a3ab3546c1a735432d03/resnet50_finetune_60_epochs_lr_decay_after_30_start_resnet50_train_45_epochs_combined_IN_SF-ca06340c.pth.tar',\n",
    "    }\n",
    "\n",
    "    model = torchvision.models.resnet50(pretrained=False)\n",
    "    model = torch.nn.DataParallel(model)#.cuda()\n",
    "    checkpoint = model_zoo.load_url(model_urls[model_name], map_location='cpu')\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "for model in ['resnet50_trained_on_SIN', 'resnet50_trained_on_SIN_and_IN', 'resnet50_trained_on_SIN_and_IN_then_finetuned_on_IN']:\n",
    "    print('Model: {}'.format(model))\n",
    "    model = load_model(model)\n",
    "    model.eval()\n",
    "    test_model(model)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hook and Hooker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:15:19.280068Z",
     "start_time": "2019-01-29T15:15:19.256154Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_plot_index(name, index, normalize, plot=False):\n",
    "    def print_output(self, input, output):\n",
    "        data = output.data.squeeze()\n",
    "        if self.__class__.__name__ != 'Linear':\n",
    "            data = data.norm(dim=(1, 2))\n",
    "        if normalize:\n",
    "            data = data.unsqueeze(0)\n",
    "            data = data.renorm(1, 0, 1)\n",
    "            data = data.squeeze()\n",
    "        data = data.cpu().numpy()\n",
    "        \n",
    "        # value\n",
    "        activations[name] = data\n",
    "        \n",
    "        # plot\n",
    "        if plot:\n",
    "            plt.subplot(*index)\n",
    "            plt.plot(data)\n",
    "            plt.fill_between(range(len(data)), data)\n",
    "            plt.grid(True)\n",
    "            plt.title(name)\n",
    "    return print_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add hooks to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:15:19.314133Z",
     "start_time": "2019-01-29T15:15:19.283772Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_hooks(model, hooker, nrows=2, ncols=2, normalize=False):\n",
    "    names = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        name = name.split('.')\n",
    "        name.pop()\n",
    "        name = '.'.join(name)\n",
    "        names[name] = None\n",
    "\n",
    "    names = list(names)\n",
    "    for index, name in enumerate(names):\n",
    "        module = rgetattr(model, name)\n",
    "        module.register_forward_hook(hooker(name, (nrows, ncols, index + 1), normalize))\n",
    "\n",
    "# add hooks to resnet50\n",
    "add_hooks(resnet50, assign_plot_index, nrows=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:15:19.354541Z",
     "start_time": "2019-01-29T15:15:19.335656Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values_directory = os.path.join('results', 'elephant-cat', 'activation-values')\n",
    "os.makedirs(values_directory, exist_ok=True)\n",
    "\n",
    "# for datapoint_index, datapoint in enumerate(elephant_cat_dataset):\n",
    "#     activations = {}\n",
    "#     top_1, top_5, top_all = predict(resnet50, elephant_cat_dataset, datapoint_index, None, None)\n",
    "#     predicted_class, prediction_description, prediction_probability = top_1\n",
    "#     true_class = datapoint[2]\n",
    "#     values_path = os.path.join(values_directory, '{}-{}-{}.pickle'.format(datapoint_index, true_class, predicted_class))\n",
    "#     pickle.dump(activations, open(values_path, 'wb'))\n",
    "\n",
    "def get_sort_key(name):\n",
    "    return int(name.split('/')[-1].split('.')[0].split('-')[0])\n",
    "\n",
    "activations_file_list = sorted(\n",
    "    [os.path.join(values_directory, file) for file in listdir(values_directory)],\n",
    "    key=get_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T15:42:23.678213Z",
     "start_time": "2019-01-29T15:42:23.647164Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_activations(activations, datapoint_index, true_class, predicted_class):\n",
    "    activation_grid = PlotGrid(figsize=(9,90))\n",
    "    for index, name in enumerate(activations):\n",
    "        data = activations[name]\n",
    "        activation_grid.plot((54, 2, index+1), data, title=name)\n",
    "\n",
    "    # plot image\n",
    "    activation_grid.plot(\n",
    "        (54, 2, 108),\n",
    "        toImage(elephant_cat_dataset[datapoint_index][1]),\n",
    "        title='True: {}\\n Predicted: {}'.format(\n",
    "            elephant_cat_dataset[datapoint_index][3],\n",
    "            elephant_cat_dataset.descriptions[predicted_class]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # save figure\n",
    "    activation_grid.savefig('{}-{}-{}.png'.format(datapoint_index, true_class, predicted_class))\n",
    "\n",
    "\n",
    "def load_activations(activation_file_index):\n",
    "    activations_file_path = activations_file_list[activation_file_index]\n",
    "    imagenet_val_index, true_class, predicted_class = activations_file_list[activation_file_index].split('/')[-1].split('.')[0].split('-')\n",
    "    return pickle.load(open(activations_file_path, 'rb')), int(imagenet_val_index), int(true_class), int(predicted_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-29T15:42:33.385Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, name in enumerate(activations_file_list):\n",
    "    activations, datapoint_index, true_class, predicted_class = load_activations(index)\n",
    "    plot_activations(activations, datapoint_index, true_class, predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:30:14.496177Z",
     "start_time": "2019-01-29T19:30:14.475923Z"
    }
   },
   "outputs": [],
   "source": [
    "def JSDiv(p, q):\n",
    "    return torch.nn.KLDivLoss(reduction='sum')(p.log(), q) + torch.nn.KLDivLoss(reduction='sum')(q.log(), p)\n",
    "\n",
    "# test inputs\n",
    "p = torch.FloatTensor([0.3, 0.6, 0.1])\n",
    "q = torch.FloatTensor([0.4, 0.5, 0.1])\n",
    "\n",
    "# test call\n",
    "print('{0:.4f} JS Divergence'.format(JSDiv(p, q).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:30:16.430615Z",
     "start_time": "2019-01-29T19:30:16.415927Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_layer_activation(activations, layer_name):\n",
    "    data = torch.from_numpy(activations[layer_name])\n",
    "    if layer_name == 'fc':\n",
    "        data = torch.nn.Softmax(dim=0)(data)\n",
    "    else:\n",
    "        data = data.unsqueeze(0)\n",
    "        data = data.renorm(1, 0, 1)\n",
    "        data = data.squeeze()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:43:34.841359Z",
     "start_time": "2019-01-29T19:43:34.809607Z"
    }
   },
   "outputs": [],
   "source": [
    "activations_1, _, _, _ = load_activations(1)\n",
    "activations_2, _, _, _ = load_activations(2)\n",
    "\n",
    "layer_names = list(activations_2.keys())\n",
    "# regex = re.compile(r'conv1|fc')\n",
    "# layer_names = list(filter(regex.search, layer_names))\n",
    "# layer_indices = [0, 1, 4, 8, 14, 17]\n",
    "# layer_names = [layer_names[i] for i in layer_indices]\n",
    "layer_index = -2\n",
    "\n",
    "p = get_layer_activation(activations_1, layer_names[layer_index])\n",
    "q = get_layer_activation(activations_2, layer_names[layer_index])\n",
    "\n",
    "assert np.isclose(p.sum().item(), 1), 'activations (p) is not a distribution'\n",
    "assert np.isclose(q.sum().item(), 1), 'activations (q) is not a distribution'\n",
    "\n",
    "print('{0:.4f} JS Divergence of activations at layer \"{1}\"'.format(JSDiv(q, p).item(), layer_names[layer_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate divergence for multiple images given a reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:43:35.662886Z",
     "start_time": "2019-01-29T19:43:35.643989Z"
    }
   },
   "outputs": [],
   "source": [
    "def activation_divergence(target_index, compare_indices, layer_name):\n",
    "    activations, imagenet_val_index, true_class, predicted_class = load_activations(target_index)\n",
    "    p = get_layer_activation(activations, layer_name)\n",
    "    divergence_information = []\n",
    "    for compare_index in compare_indices:\n",
    "        activations_, imagenet_val_index_, true_class_, predicted_class_  = load_activations(compare_index)\n",
    "        q = get_layer_activation(activations_, layer_name)\n",
    "        divergence_information.append((\n",
    "            JSDiv(p, q).item(),\n",
    "            true_class==true_class_,\n",
    "            predicted_class==predicted_class_,\n",
    "            true_class==predicted_class,\n",
    "            imagenet_val_index,\n",
    "            imagenet_val_index_\n",
    "        ))\n",
    "    return divergence_information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:43:35.942270Z",
     "start_time": "2019-01-29T19:43:35.885587Z"
    }
   },
   "outputs": [],
   "source": [
    "divergence_values_directory = os.path.join('results', 'elephant-cat', 'divergence-values')\n",
    "os.makedirs(divergence_values_directory, exist_ok=True)\n",
    "\n",
    "divergence_figure_directory = os.path.join('results', 'elephant-cat', 'divergence-plots')\n",
    "os.makedirs(divergence_figure_directory, exist_ok=True)\n",
    "\n",
    "def get_sort_key(name):\n",
    "    return int(name.split('/')[-1].split('.')[0].split('-')[1])\n",
    "\n",
    "divergences_file_list = sorted(\n",
    "    [os.path.join(divergence_values_directory, file) for file in listdir(divergence_values_directory)],\n",
    "    key=get_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate/Plot activation divergence at specified layers given the reference image over the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T23:14:54.054363Z",
     "start_time": "2019-01-29T23:14:54.004012Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_divergences(datapoint_index, save=True):\n",
    "    other_indices = list(range(0, len(elephant_cat_dataset)))\n",
    "    other_indices.remove(datapoint_index)\n",
    "    divergence_information = {}\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergence_information[layer_name] = activation_divergence(datapoint_index, other_indices, layer_name)\n",
    "    if save:\n",
    "        values_path = os.path.join(divergence_values_directory, 'divergence-{}.pickle'.format(datapoint_index))\n",
    "        pickle.dump(divergence_information, open(values_path, 'wb'))\n",
    "    return divergence_information\n",
    "\n",
    "\n",
    "def load_divergences(divergences_file_index):\n",
    "    divergences_file_path = divergences_file_list[divergences_file_index]\n",
    "    _, imagenet_val_index = divergences_file_list[divergences_file_index].split('/')[-1].split('.')[0].split('-')\n",
    "    return pickle.load(open(divergences_file_path, 'rb')), int(imagenet_val_index)\n",
    "\n",
    "\n",
    "def plot_divergences(divergence_information, datapoint_index, cols=2, same_class_size=100, other_class_size=10, save=True):\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergences = [ x[0] for x in divergence_information[layer_name] ]\n",
    "        class_matches = [ int(x[1]) for x in divergence_information[layer_name] ]\n",
    "        class_matches_size = [ same_class_size if x==1 else other_class_size for x in class_matches ]\n",
    "        plt.subplot(len(layer_names)//cols + len(layer_names)%cols, cols, index)\n",
    "        plt.scatter(range(len(divergences)), divergences, s=class_matches_size, c=class_matches)\n",
    "        other_indices = list(range(0, len(elephant_cat_dataset)))\n",
    "        other_indices.remove(datapoint_index)\n",
    "        plt.xticks(np.arange(len(elephant_cat_datapoints) - 1), [elephant_cat_datapoints[other_index][3] for other_index in other_indices], rotation=45)\n",
    "        plt.title(layer_name)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(divergence_figure_directory, 'divergence-{}.png'.format(datapoint_index)), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Min/Mean/Max Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T20:33:04.460546Z",
     "start_time": "2019-01-29T20:33:04.433476Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_zeros(array):\n",
    "    return array[np.flatnonzero(array)]\n",
    "\n",
    "def calculate_divergence_metrics(divergence_information):\n",
    "    metrics = {}\n",
    "    for index, layer_name in enumerate(layer_names, 1):\n",
    "        divergences = np.array([ x[0] for x in divergence_information[layer_name] ])\n",
    "        class_matches = np.array([ int(x[1]) for x in divergence_information[layer_name] ])\n",
    "        other_class = (class_matches + 1) % 2\n",
    "        class_divergences = remove_zeros(divergences * class_matches)\n",
    "        other_divergences = remove_zeros(divergences * other_class)\n",
    "        metrics[layer_name] = {\n",
    "            'same': {\n",
    "                'min': class_divergences.min(),\n",
    "                'mean': class_divergences.mean(),\n",
    "                'max': class_divergences.max()\n",
    "            },\n",
    "            'other': {\n",
    "                'min': other_divergences.min(),\n",
    "                'mean': other_divergences.mean(),\n",
    "                'max': other_divergences.max()\n",
    "            }\n",
    "        }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate activation divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:43:45.193391Z",
     "start_time": "2019-01-29T19:43:38.580899Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "divergence_metrics = {}\n",
    "\n",
    "for datapoint_index in range(len(elephant_cat_dataset)):\n",
    "    divergence_information = calculate_divergences(datapoint_index)\n",
    "#     divergence_metrics[datapoint_index] = calculate_divergence_metrics(divergence_information)\n",
    "#     pp.pprint(divergence_information)\n",
    "\n",
    "metrics_path = os.path.join(divergence_values_directory, 'divergence-metrics.pickle')\n",
    "pickle.dump(divergence_metrics, open(metrics_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot activation divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T23:43:03.686693Z",
     "start_time": "2019-01-29T23:14:54.178780Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, name in enumerate(divergences_file_list):\n",
    "    plt.figure(figsize=(9, len(layer_names) * 2))\n",
    "    divergence_information, datapoint_index = load_divergences(index)\n",
    "    plot_divergences(divergence_information, datapoint_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
